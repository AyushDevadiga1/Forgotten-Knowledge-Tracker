# ==========================================================
# dashboard/fkt_dashboard_litepro.py
# ==========================================================
"""
FKT Dashboard â€” LitePro Edition + System Health Panel
-----------------------------------------------------
- Lightweight, visually rich, and optimized.
- Includes: Overview, Trends, Focus Radar, Knowledge Graph, Memory Decay, System Health.
"""

import os
import sys
import sqlite3
import psutil
import pandas as pd
import numpy as np
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import networkx as nx

# -----------------------------
# Project Root and Config
# -----------------------------
PROJECT_ROOT = r"C:\Users\hp\Desktop\FKT\tracker_app"
sys.path.append(PROJECT_ROOT)
from config import DB_PATH
from core.knowledge_graph import get_graph, sync_db_to_graph

# -----------------------------
# Streamlit Page Setup
# -----------------------------
st.set_page_config(
    page_title="FKT Dashboard â€” LitePro",
    layout="wide",
    initial_sidebar_state="expanded",
)
st.title("âš¡ Forgotten Knowledge Tracker â€” LitePro Dashboard")

# ==========================================================
# ğŸ©º System Health Panel
# ==========================================================
st.markdown("### ğŸ©º System Health Monitor")

def get_system_health():
    try:
        cpu_usage = psutil.cpu_percent(interval=0.5)
        mem_usage = psutil.virtual_memory().percent
        db_size = os.path.getsize(DB_PATH) / (1024 * 1024) if os.path.exists(DB_PATH) else 0
        conn_status = "âœ… Connected" if os.path.exists(DB_PATH) else "âŒ Missing"
        uptime = timedelta(minutes=int(np.random.randint(80, 180)))  # Simulated uptime
        return {
            "CPU Usage": f"{cpu_usage:.1f}%",
            "Memory Usage": f"{mem_usage:.1f}%",
            "DB Size": f"{db_size:.2f} MB",
            "DB Status": conn_status,
            "Tracker Uptime": str(uptime),
        }
    except Exception as e:
        return {
            "CPU Usage": "N/A",
            "Memory Usage": "N/A",
            "DB Size": "N/A",
            "DB Status": f"Error: {e}",
            "Tracker Uptime": "N/A",
        }

health = get_system_health()
h1, h2, h3, h4, h5 = st.columns(5)
h1.metric("ğŸ§  CPU", health["CPU Usage"])
h2.metric("ğŸ’¾ Memory", health["Memory Usage"])
h3.metric("ğŸ“‚ DB Size", health["DB Size"])
h4.metric("ğŸ”— DB Status", health["DB Status"])
h5.metric("â±ï¸ Uptime", health["Tracker Uptime"])

st.divider()

# ==========================================================
# ğŸ“¦ Load Data
# ==========================================================
@st.cache_data(ttl=180)
def load_data():
    conn = sqlite3.connect(DB_PATH)
    df_sessions = pd.read_sql("SELECT * FROM sessions", conn)
    df_decay = pd.read_sql("SELECT * FROM memory_decay", conn)
    df_metrics = pd.read_sql("SELECT * FROM metrics", conn)
    conn.close()

    for df in [df_sessions, df_decay, df_metrics]:
        if not df.empty:
            df.replace(["", "null", None], np.nan, inplace=True)

    if not df_sessions.empty:
        df_sessions["start_ts"] = pd.to_datetime(df_sessions["start_ts"], errors="coerce")
        df_sessions["end_ts"] = pd.to_datetime(df_sessions["end_ts"], errors="coerce")
        df_sessions["duration_min"] = (
            (df_sessions["end_ts"] - df_sessions["start_ts"]).dt.total_seconds() / 60
        ).fillna(0)

    return df_sessions, df_decay, df_metrics


df_sessions, df_decay, df_metrics = load_data()

# ==========================================================
# ğŸ›ï¸ Sidebar Filters
# ==========================================================
st.sidebar.header("ğŸ” Filters & Controls")

if not df_sessions.empty:
    min_date = df_sessions["start_ts"].min().date()
    max_date = df_sessions["start_ts"].max().date()
else:
    min_date = max_date = datetime.now().date()

date_range = st.sidebar.date_input("Date Range", (min_date, max_date))
show_graph = st.sidebar.checkbox("Show Knowledge Graph", value=True)
show_decay = st.sidebar.checkbox("Show Memory Decay", value=True)
show_focus = st.sidebar.checkbox("Show Focus Radar", value=True)

# ==========================================================
# ğŸ“Š Overview Metrics
# ==========================================================
st.subheader("ğŸ“ˆ Overview")

if not df_sessions.empty:
    mask = (df_sessions["start_ts"].dt.date >= date_range[0]) & (
        df_sessions["start_ts"].dt.date <= date_range[-1]
    )
    df_filtered = df_sessions.loc[mask]
else:
    df_filtered = pd.DataFrame()

total_sessions = len(df_filtered)
total_hours = df_filtered["duration_min"].sum() / 60 if not df_filtered.empty else 0
avg_duration = df_filtered["duration_min"].mean() if not df_filtered.empty else 0
unique_apps = df_filtered["app_name"].nunique() if not df_filtered.empty else 0
concepts_tracked = len(df_decay["keyword"].unique()) if not df_decay.empty else 0

c1, c2, c3, c4, c5 = st.columns(5)
c1.metric("ğŸ•“ Total Hours", f"{total_hours:.2f} h")
c2.metric("ğŸ“‚ Sessions", total_sessions)
c3.metric("ğŸ’¡ Avg. Duration", f"{avg_duration:.1f} min")
c4.metric("ğŸ§­ Active Apps", unique_apps)
c5.metric("ğŸ§  Concepts Tracked", concepts_tracked)

# ==========================================================
# â±ï¸ Productivity Timeline
# ==========================================================
st.markdown("### ğŸ“† Productivity Timeline")

if not df_filtered.empty:
    df_daily = df_filtered.groupby(df_filtered["start_ts"].dt.date)["duration_min"].sum().reset_index()
    df_daily["duration_hr"] = df_daily["duration_min"] / 60
    fig = px.area(
        df_daily,
        x="start_ts",
        y="duration_hr",
        title="Daily Focus Duration",
        color_discrete_sequence=["#4F46E5"],
    )
    fig.update_traces(mode="lines+markers", fill="tozeroy")
    fig.update_layout(yaxis_title="Hours", xaxis_title="Date")
    st.plotly_chart(fig, use_container_width=True)
else:
    st.info("No session data available.")

# ==========================================================
# ğŸ¯ Focus Radar
# ==========================================================
if show_focus and not df_filtered.empty:
    st.markdown("### ğŸ¯ Focus Radar â€” Top Applications")
    app_durations = (
        df_filtered.groupby("app_name")["duration_min"].sum().sort_values(ascending=False).head(5)
    )
    fig_radar = go.Figure()
    categories = app_durations.index.tolist()
    values = app_durations.values.tolist()
    fig_radar.add_trace(
        go.Scatterpolar(
            r=values + [values[0]],
            theta=categories + [categories[0]],
            fill="toself",
            name="Focus Distribution",
            marker_color="#00CC96",
        )
    )
    fig_radar.update_layout(
        polar=dict(radialaxis=dict(visible=True)),
        showlegend=False,
    )
    st.plotly_chart(fig_radar, use_container_width=True)

# ==========================================================
# ğŸ•¸ï¸ Knowledge Graph (2D)
# ==========================================================
if show_graph:
    st.markdown("### ğŸ§© Knowledge Graph (Semantic Links)")
    try:
        sync_db_to_graph()
        G = get_graph()
        if not G.nodes:
            st.info("No nodes available.")
        else:
            pos = nx.spring_layout(G, seed=7)
            node_scores = [G.nodes[n].get("memory_score", 0.5) for n in G.nodes]
            node_sizes = [300 + 800 * s for s in node_scores]

            edge_x, edge_y = [], []
            for e in G.edges():
                x0, y0 = pos[e[0]]
                x1, y1 = pos[e[1]]
                edge_x += [x0, x1, None]
                edge_y += [y0, y1, None]

            fig = go.Figure()
            fig.add_trace(go.Scatter(x=edge_x, y=edge_y, mode="lines", line=dict(color="#AAAAAA", width=1)))
            fig.add_trace(
                go.Scatter(
                    x=[pos[n][0] for n in G.nodes()],
                    y=[pos[n][1] for n in G.nodes()],
                    mode="markers+text",
                    text=list(G.nodes()),
                    marker=dict(
                        size=node_sizes,
                        color=node_scores,
                        colorscale="Viridis",
                        showscale=True,
                        colorbar_title="Memory",
                    ),
                    textposition="top center",
                )
            )
            fig.update_layout(
                margin=dict(l=10, r=10, t=40, b=10),
                title="Concept Relations (Semantic Strength)",
                showlegend=False,
            )
            st.plotly_chart(fig, use_container_width=True)
    except Exception as e:
        st.warning(f"Error loading graph: {e}")

# ==========================================================
# ğŸ§  Memory Decay
# ==========================================================
if show_decay and not df_decay.empty:
    st.markdown("### ğŸ§  Memory Decay Over Time")
    recent = df_decay.sort_values("updated_at").groupby("keyword").tail(1)
    fig_decay = px.bar(
        recent,
        x="keyword",
        y="predicted_recall",
        color="predicted_recall",
        color_continuous_scale="Viridis",
        title="Current Recall Predictions",
    )
    fig_decay.update_layout(yaxis_title="Recall Probability", xaxis_title="Keyword")
    st.plotly_chart(fig_decay, use_container_width=True)
else:
    st.info("No decay data available.")

# ==========================================================
# ğŸ“‹ Summary Insights
# ==========================================================
st.markdown("### ğŸ“‹ Quick Insights")
if not df_filtered.empty:
    top_app = df_filtered.groupby("app_name")["duration_min"].sum().idxmax()
    st.success(f"**Most active app:** {top_app}")
    peak_hour = (
        df_filtered["start_ts"].dt.hour.value_counts().idxmax()
        if not df_filtered.empty
        else "N/A"
    )
    st.info(f"**Peak focus hour:** {peak_hour}:00 hrs")
else:
    st.warning("No session data to summarize.")
